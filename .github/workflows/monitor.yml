name: ä¸œæ¨ªInn å¼ºåŠ›ç›‘æ§ç‰ˆ

on:
  schedule:
    - cron: '*/30 * * * *'
  workflow_dispatch:

jobs:
  check_rooms:
    runs-on: ubuntu-latest
    steps:
      - name: æ‹‰å–ä»£ç 
        uses: actions/checkout@v3

      - name: è®¾ç½® Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: å®‰è£…ä¾èµ–
        run: pip install requests beautifulsoup4 resend

      - name: æ‰¹é‡è¿è¡Œç›‘æ§
        env:
          RESEND_API_KEY: ${{ secrets.RESEND_API_KEY }}
          USER_EMAIL: ${{ secrets.USER_EMAIL }}
        run: |
          python -c "
          import requests
          from bs4 import BeautifulSoup
          import os
          import resend
          import time
          from urllib.parse import urlparse, parse_qs

          # é…ç½®
          resend.api_key = os.environ.get('RESEND_API_KEY')
          user_email = os.environ.get('USER_EMAIL')
          
          # å¼ºåŠ›ä¼ªè£…å¤´ (æ¨¡æ‹ŸçœŸå®çš„ä¸­æ–‡æµè§ˆå™¨)
          headers = {
              'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
              'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
              'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
              'Referer': 'https://www.toyoko-inn.com/',
              'Cache-Control': 'no-cache',
              'Pragma': 'no-cache'
          }

          try:
              with open('urls.txt', 'r') as f:
                  urls = [line.strip() for line in f if line.strip()]
          except FileNotFoundError:
              print('âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ° urls.txt')
              exit(1)

          print(f'ğŸ“‹ å¯åŠ¨ç›‘æ§: {len(urls)} ä¸ªä»»åŠ¡ (å·²å¯ç”¨å¼ºåŠ›æ¨¡å¼)\n')
          
          found_list = []

          for i, url in enumerate(urls):
              # URL å‚æ•°è§£æ
              try:
                  parsed = urlparse(url)
                  params = parse_qs(parsed.query)
                  hotel_id = params.get('hotel', ['æœªçŸ¥'])[0]
                  checkin_date = params.get('start', ['æœªçŸ¥'])[0]
              except:
                  hotel_id = 'æœªçŸ¥'
                  checkin_date = 'æœªçŸ¥'

              print(f'[{i+1}/{len(urls)}] ğŸ¨ {hotel_id} | ğŸ“… {checkin_date}')
              
              try:
                  # å…è®¸é‡å®šå‘ï¼Œå¢åŠ è¶…æ—¶
                  resp = requests.get(url, headers=headers, timeout=45)
                  
                  if resp.status_code != 200:
                      print(f'      âŒ çŠ¶æ€ç å¼‚å¸¸: {resp.status_code}')
                      continue

                  soup = BeautifulSoup(resp.text, 'html.parser')
                  
                  # === è¯Šæ–­ä¿¡æ¯ ===
                  # è·å–ç½‘é¡µæ ‡é¢˜ï¼Œç¡®è®¤æ˜¯å¦è·³åˆ°äº†é”™è¯¯çš„é¡µé¢ï¼ˆæ¯”å¦‚'Access Denied' æˆ– 'Select Language'ï¼‰
                  page_title = soup.title.string.strip() if soup.title else 'æ— æ ‡é¢˜'
                  
                  # === æ ¸å¿ƒåˆ¤å®š (æ”¾å®½æ ‡å‡†) ===
                  # 1. æŸ¥æ‰¾åŒ…å« reserve çš„é“¾æ¥
                  reserve_links = soup.find_all(lambda tag: tag.name == 'a' and tag.get('href') and 'reserve' in tag.get('href'))
                  
                  # 2. è¾…åŠ©åˆ¤å®šï¼šæŸ¥æ‰¾ä»·æ ¼æ ‡ç­¾ (åªè¦æ˜¾ç¤ºä»·æ ¼é€šå¸¸å°±æ„å‘³ç€å¯è®¢)
                  # ä¸œæ¨ªçš„ä»·æ ¼é€šå¸¸åŒ…å« 'Â¥' æˆ– 'CNY' ä¸”åœ¨ class ä¸º 'plan-price' æˆ–ç±»ä¼¼ç»“æ„ä¸­
                  # è¿™é‡Œç®€å•ç²—æš´æŸ¥å…¨é¡µæ˜¯å¦æœ‰ä»·æ ¼ç¬¦å· (æ’é™¤é¡µè„šç­‰æ— å…³åŒºåŸŸçš„è¯éœ€è¦æ›´ç»†ï¼Œå…ˆç²—æŸ¥)
                  has_price = 'Â¥' in resp.text or 'CNY' in resp.text
                  
                  is_available = False
                  if len(reserve_links) > 0:
                      is_available = True
                  
                  if is_available:
                      print(f'      ğŸ‰ å‘ç°ç©ºæˆ¿! (æ ‡é¢˜: {page_title})')
                      found_list.append({
                          'id': hotel_id,
                          'date': checkin_date,
                          'url': url,
                          'title': page_title
                      })
                  else:
                      print(f'      ğŸ˜´ æš‚æ— ç©ºæˆ¿ (é¡µé¢æ ‡é¢˜: {page_title})')
                      # å¦‚æœæ ‡é¢˜çœ‹èµ·æ¥ä¸å¯¹åŠ²ï¼Œæ‰“å°å‡ºæ¥æé†’
                      if 'Toyoko' not in page_title and 'ä¸œæ¨ª' not in page_title:
                          print(f'      âš ï¸ è­¦å‘Š: é¡µé¢æ ‡é¢˜çœ‹èµ·æ¥ä¸åƒä¸œæ¨ªå®˜ç½‘ï¼Œå¯èƒ½è¢«æ‹¦æˆªæˆ–è·³è½¬ã€‚')

                  time.sleep(3) # ç¨å¾®æ…¢ç‚¹ï¼Œé˜²æ­¢è¿ç»­è¯·æ±‚è¢«å°

              except Exception as e:
                  print(f'      âŒ è„šæœ¬å‡ºé”™: {e}')
              
              print('-'*40)

          # å‘é€é‚®ä»¶é€»è¾‘
          if found_list:
              print('\nğŸ“§ æ­£åœ¨å‘é€é€šçŸ¥...')
              email_html = '<h3>ğŸ‰ å‘ç°ç©ºæˆ¿ï¼š</h3><ul>'
              for item in found_list:
                  email_html += f'<li><strong>{item["date"]} (åº—å·{item["id"]})</strong><br><a href="{item["url"]}">ç‚¹å‡»é¢„è®¢</a><br><small>ç½‘é¡µæ ‡é¢˜: {item["title"]}</small></li>'
              email_html += '</ul>'

              try:
                  if resend.api_key:
                      resend.Emails.send({
                        'from': 'onboarding@resend.dev',
                        'to': user_email,
                        'subject': f'ã€æœ‰æˆ¿ã€‘{found_list[0]["date"]} ç­‰ {len(found_list)} ä¸ªè¡Œç¨‹',
                        'html': email_html
                      })
                      print('âœ… é‚®ä»¶å‘é€æˆåŠŸ')
              except Exception as e:
                  print('âŒ é‚®ä»¶å¤±è´¥:', e)
          else:
              print('\nğŸ ç»“æŸï¼Œæ— æ–°å‘ç°ã€‚')
          "
