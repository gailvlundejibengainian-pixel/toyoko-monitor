name: ä¸œæ¨ªInn æ‰¹é‡ç›‘æ§

on:
  schedule:
    - cron: '*/30 * * * *'  # æ¯30åˆ†é’Ÿè¿è¡Œä¸€æ¬¡
  workflow_dispatch:        # æ”¯æŒæ‰‹åŠ¨ç‚¹å‡»æŒ‰é’®è¿è¡Œ

jobs:
  check_rooms:
    runs-on: ubuntu-latest
    steps:
      - name: æ‹‰å–ä»£ç  (è·å– urls.txt)
        uses: actions/checkout@v3

      - name: è®¾ç½® Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: å®‰è£…ä¾èµ–
        run: pip install requests beautifulsoup4 resend

      - name: æ‰¹é‡è¿è¡Œç›‘æ§
        env:
          RESEND_API_KEY: ${{ secrets.RESEND_API_KEY }}
          USER_EMAIL: ${{ secrets.USER_EMAIL }}
        run: |
          python -c "
          import requests
          from bs4 import BeautifulSoup
          import os
          import resend
          import time
          from urllib.parse import urlparse, parse_qs

          # 1. é…ç½® Resend
          resend.api_key = os.environ.get('RESEND_API_KEY')
          user_email = os.environ.get('USER_EMAIL')

          # 2. è¯»å– urls.txt
          try:
              with open('urls.txt', 'r') as f:
                  urls = [line.strip() for line in f if line.strip()]
          except FileNotFoundError:
              print('âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ° urls.txt æ–‡ä»¶')
              exit(1)

          print(f'ğŸ“‹ è®¡åˆ’ç›‘æ§ {len(urls)} ä¸ªä»»åŠ¡...\n')
          print('='*50)

          headers = {
              'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
          }

          found_list = []

          # 3. å¾ªç¯æ£€æŸ¥
          for i, url in enumerate(urls):
              # --- è§£æ URL å‚æ•° (è®©æ—¥å¿—æ›´å¥½çœ‹) ---
              try:
                  parsed = urlparse(url)
                  params = parse_qs(parsed.query)
                  hotel_id = params.get('hotel', ['æœªçŸ¥ç¼–å·'])[0]
                  checkin_date = params.get('start', ['æœªçŸ¥æ—¥æœŸ'])[0]
              except:
                  hotel_id = 'æœªçŸ¥'
                  checkin_date = 'æœªçŸ¥'

              print(f'[{i+1}/{len(urls)}] ğŸ¨ é…’åº—:{hotel_id} | ğŸ“… æ—¥æœŸ:{checkin_date}')
              
              try:
                  resp = requests.get(url, headers=headers, timeout=30)
                  if resp.status_code != 200:
                      print(f'      âŒ è®¿é—®å¤±è´¥: {resp.status_code}')
                      continue

                  soup = BeautifulSoup(resp.text, 'html.parser')
                  
                  # å°è¯•è·å–ç½‘é¡µé‡Œçš„é…’åº—å…·ä½“åç§° (ä½œä¸ºè¡¥å……)
                  page_title = soup.title.string.strip() if soup.title else ''
                  # ç®€å•çš„æ¸…æ´—é€»è¾‘ï¼Œå»æ‰é€šç”¨çš„åç¼€
                  hotel_name = page_title.replace(' - ä¸œæ¨ªINN', '').replace('ï½œé…’åº—Â·å•†åŠ¡é…’åº—é¢„è®¢', '')
                  if not hotel_name: hotel_name = f'åº—å· {hotel_id}'

                  # æ ¸å¿ƒåˆ¤æ–­é€»è¾‘ (æŸ¥æ‰¾é¢„è®¢æŒ‰é’®)
                  has_room = False
                  # æŸ¥æ‰¾æ‰€æœ‰ href åŒ…å« /reserve/input çš„é“¾æ¥
                  booking_links = soup.find_all(lambda tag: tag.name == 'a' and tag.get('href') and '/reserve/input' in tag.get('href'))
                  
                  if booking_links:
                      has_room = True
                  
                  if has_room:
                      print(f'      ğŸ‰ å‘ç°ç©ºæˆ¿! ({hotel_name})')
                      found_list.append({
                          'name': hotel_name,
                          'date': checkin_date,
                          'url': url,
                          'count': len(booking_links)
                      })
                  else:
                      print('      ğŸ˜´ æš‚æ— ç©ºæˆ¿')
                  
                  # ç¤¼è²Œå»¶æ—¶ï¼Œé˜²æ­¢è¯·æ±‚å¤ªå¿«è¢«å° IP
                  time.sleep(2)

              except Exception as e:
                  print(f'      âŒ è„šæœ¬å‡ºé”™: {e}')
              
              print('-'*50)

          # 4. å‘é€é€šçŸ¥ (é‚®ä»¶å†…å®¹ä¼˜åŒ–)
          if found_list:
              print('\nğŸ“§ æ­£åœ¨å‘é€é€šçŸ¥é‚®ä»¶...')
              
              # æ„å»ºæ¸…æ™°çš„é‚®ä»¶ HTML
              email_body = '<h3>ğŸ‰ ä»¥ä¸‹è¡Œç¨‹å‘ç°ç©ºæˆ¿ï¼Œè¯·é€ŸæŠ¢ï¼š</h3><hr>'
              for item in found_list:
                  email_body += f'''
                  <div style='margin-bottom: 15px; padding: 10px; border: 1px solid #ddd; border-radius: 5px;'>
                      <p><strong>ğŸ¨ é…’åº—:</strong> {item['name']}</p>
                      <p><strong>ğŸ“… æ—¥æœŸ:</strong> {item['date']}</p>
                      <p><strong>ğŸ”¢ æˆ¿å‹æ•°:</strong> {item['count']} ä¸ªé€‰é¡¹</p>
                      <p><a href='{item['url']}' style='background-color: #28a745; color: white; padding: 5px 10px; text-decoration: none; border-radius: 3px;'>ğŸ‘‰ ç‚¹å‡»ç›´æ¥é¢„è®¢</a></p>
                  </div>
                  '''
              
              try:
                  if resend.api_key:
                      r = resend.Emails.send({
                        'from': 'onboarding@resend.dev',
                        'to': user_email,
                        'subject': f'ã€æœ‰æˆ¿æé†’ã€‘{found_list[0]["date"]} - {found_list[0]["name"]} ç­‰',
                        'html': email_body
                      })
                      print('âœ… é‚®ä»¶å‘é€æˆåŠŸï¼ID:', r)
                  else:
                      print('âš ï¸ æœªé…ç½® RESEND_API_KEYï¼Œè·³è¿‡å‘é€é‚®ä»¶')
              except Exception as e:
                  print('âŒ é‚®ä»¶å‘é€å¤±è´¥:', e)
          else:
              print('\nğŸ æœ¬æ¬¡è¿è¡Œç»“æŸï¼Œæœªå‘ç°ç©ºæˆ¿ã€‚')
          "
