name: ä¸œæ¨ªInn æ‰¹é‡ç›‘æ§

on:
  schedule:
    - cron: '*/30 * * * *'  # æ¯30åˆ†é’Ÿè¿è¡Œä¸€æ¬¡
  workflow_dispatch:        # æ”¯æŒæ‰‹åŠ¨è¿è¡Œ

jobs:
  check_rooms:
    runs-on: ubuntu-latest
    steps:
      - name: æ‹‰å–ä»£ç  (è·å– urls.txt)
        uses: actions/checkout@v3

      - name: è®¾ç½® Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: å®‰è£…ä¾èµ–
        run: pip install requests beautifulsoup4 resend

      - name: æ‰¹é‡è¿è¡Œç›‘æ§
        env:
          RESEND_API_KEY: ${{ secrets.RESEND_API_KEY }}
          USER_EMAIL: ${{ secrets.USER_EMAIL }}
        run: |
          python -c "
          import requests
          from bs4 import BeautifulSoup
          import os
          import resend
          import time

          # 1. é…ç½® Resend
          resend.api_key = os.environ['RESEND_API_KEY']
          user_email = os.environ['USER_EMAIL']

          # 2. è¯»å– urls.txt
          try:
              with open('urls.txt', 'r') as f:
                  urls = [line.strip() for line in f if line.strip()]
          except FileNotFoundError:
              print('âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ° urls.txt æ–‡ä»¶')
              exit(1)

          print(f'ğŸ“‹ è®¡åˆ’ç›‘æ§ {len(urls)} ä¸ªä»»åŠ¡...\n')

          headers = {
              'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
          }

          found_list = []

          # 3. å¾ªç¯æ£€æŸ¥
          for i, url in enumerate(urls):
              print(f'[{i+1}/{len(urls)}] æ­£åœ¨æ£€æŸ¥...')
              try:
                  resp = requests.get(url, headers=headers, timeout=30)
                  if resp.status_code != 200:
                      print(f'   âŒ è®¿é—®å¤±è´¥: {resp.status_code}')
                      continue

                  soup = BeautifulSoup(resp.text, 'html.parser')
                  
                  # æ ¸å¿ƒåˆ¤æ–­é€»è¾‘
                  has_room = False
                  if soup.find_all(lambda tag: tag.name == 'a' and tag.get('href') and '/reserve/input' in tag.get('href')):
                      has_room = True
                  
                  if has_room:
                      print('   ğŸ‰ å‘ç°ç©ºæˆ¿ï¼')
                      found_list.append(url)
                  else:
                      print('   ğŸ˜´ æš‚æ— ç©ºæˆ¿')
                  
                  # ç¤¼è²Œå»¶æ—¶ï¼Œé˜²æ­¢è¯·æ±‚å¤ªå¿«è¢«å° IP
                  time.sleep(2)

              except Exception as e:
                  print(f'   âŒ è„šæœ¬å‡ºé”™: {e}')

          # 4. å¦‚æœæœ‰å‘ç°ï¼Œå‘é€æ±‡æ€»é‚®ä»¶
          if found_list:
              print('\nğŸ“§ æ­£åœ¨å‘é€é€šçŸ¥é‚®ä»¶...')
              email_body = '<h3>ğŸ‰ ä»¥ä¸‹è¡Œç¨‹å‘ç°ç©ºæˆ¿ï¼š</h3><ul>'
              for link in found_list:
                  email_body += f'<li><a href=\'{link}\'>ç‚¹å‡»é¢„è®¢</a> (é“¾æ¥: {link})</li>'
              email_body += '</ul>'

              try:
                  r = resend.Emails.send({
                    'from': 'onboarding@resend.dev',
                    'to': user_email,
                    'subject': f'ã€æœ‰æˆ¿æé†’ã€‘å‘ç°äº† {len(found_list)} ä¸ªç©ºæˆ¿ï¼',
                    'html': email_body
                  })
                  print('âœ… é‚®ä»¶å‘é€æˆåŠŸï¼ID:', r)
              except Exception as e:
                  print('âŒ é‚®ä»¶å‘é€å¤±è´¥:', e)
          else:
              print('\nğŸ æœ¬æ¬¡è¿è¡Œç»“æŸï¼Œæœªå‘ç°ç©ºæˆ¿ã€‚')
          "
